{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 01\n",
    "\n",
    "**Alumno**: Matias Tripode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Implementar el algoritmo White Patch para librarnos de las diferencias de color de iluminación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_patch(input_image_rgb: np.ndarray) -> np.ndarray:\n",
    "    im_r, im_g, im_b = cv.split(input_image_rgb)\n",
    "    # red\n",
    "    im_r_max = im_r.max()\n",
    "    if im_r_max == 255:\n",
    "        im_r_max = np.percentile(im_r, 95)\n",
    "    # green\n",
    "    im_g_max = im_g.max()\n",
    "    if im_g_max == 255:\n",
    "        im_g_max = np.percentile(im_g, 95)\n",
    "    # blue\n",
    "    im_b_max = im_b.max()\n",
    "    if im_b_max == 255:\n",
    "        im_b_max = np.percentile(im_b, 95)\n",
    "\n",
    "    new_r = np.uint8((255/im_r_max)*im_r)\n",
    "    new_g = np.uint8((255/im_g_max)*im_g)\n",
    "    new_b = np.uint8((255/im_b_max)*im_b)\n",
    "\n",
    "    return cv.merge((new_r,new_g,new_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Mostrar los resultados obtenidos y analizar las posibles fallas (si es que las hay) en el caso de\n",
    "White patch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar alguna de las lineas para ver el procesado de la imagen con White-patch\n",
    "img_color = cv.imread('white_patch/test_blue.png')\n",
    "#img_color = cv.imread('white_patch/test_green.png')\n",
    "#img_color = cv.imread('white_patch/test_red.png')\n",
    "#img_color = cv.imread('white_patch/wp_blue.jpg')\n",
    "#img_color = cv.imread('white_patch/wp_green.png')\n",
    "#img_color = cv.imread('white_patch/wp_red.png')\n",
    "\n",
    "# Para las siguientes dos imagenes, White-patch produce la misma imagen. Ver explicacion abajo.\n",
    "#img_color = cv.imread('white_patch/wp_green2.jpg')\n",
    "#img_color = cv.imread('white_patch/wp_red2.jpg')\n",
    "\n",
    "imgRGB = cv.cvtColor(img_color, cv.COLOR_BGR2RGB)\n",
    "\n",
    "imgRGB_filtrada = white_patch(imgRGB)\n",
    "\n",
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(imgRGB, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Imagen modificada con white-patch\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(imgRGB_filtrada, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title('White-patch')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analizar las posibles fallas**\n",
    "\n",
    "Para imagenes como `wp_green2.jpg` y `wp_red2.jpg` que tienen dos canales con valores `0` o muy cercanos al `0`, el algoritmo de `White-Patch` produce la misma imagen.\n",
    "\n",
    "Por ejemplo vemos un extracto de  `wp_green2.jpg`  que practicamente tiene valores en el canal `G`:\n",
    "```\n",
    "...\n",
    "[[  3  97   3]\n",
    "  [  3  97   3]\n",
    "  [  0  92   0]\n",
    "  ...\n",
    "  [  0 252   0]\n",
    "  [  0 251   0]\n",
    "  [  0 251   0]]\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Para las imágenes img1_tp.png y img2_tp.png leerlas con OpenCV en escala de grisas y\n",
    "visualizarlas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar una imagen en modo monocromático (un canal)\n",
    "img1_tp = cv.imread('img1_tp.png', cv.IMREAD_GRAYSCALE)\n",
    "img2_tp = cv.imread('img2_tp.png', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen img1_tp\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img1_tp, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('img1_tp')\n",
    "\n",
    "# Imagen img2_tp\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img2_tp, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title('img2_tp')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Elija el numero de bins que crea conveniente y grafique su histograma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen img1_tp\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img1_tp, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('img1_tp')\n",
    "\n",
    "ax3=plt.subplot(223)\n",
    "ax3.hist(img1_tp, bins=32, edgecolor='black')\n",
    "ax3.set_title('Histograma img1_tp')\n",
    "\n",
    "# Imagen img2_tp\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img2_tp, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title('img2_tp')\n",
    "\n",
    "ax4=plt.subplot(224)\n",
    "ax4.hist(img2_tp, bins=32, edgecolor='black')\n",
    "ax4.set_title('Histograma img2_tp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparando histogramas, explicar lo que se observa**\n",
    "\n",
    "- Vemos que la distribución de intensidades de la imagen `img1_tp.png` es suave y continua. Esto indicaria que la imagen no fue modificada digitalmente.\n",
    "- En cambio vemos en el histograma de `img2_tp.png` quizas se le aplico una alteración de\n",
    "contraste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si tuviera que entrenar un modelo de clasificación/detección de imágenes, considera que puede ser de utilidad tomar como ‘features’ a los histogramas?**\n",
    "- Si tuviera que clasificar imagenes entre modificadas digitalemente y cuales no, entonces si podriamos utilizar `histogramas` como `features` (por lo visto en el punto anterior)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_ai_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
